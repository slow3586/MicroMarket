name: micromarket

x-logging: &logging
  #driver: gelf
  #options:
  #  gelf-address: "udp://host.docker.internal:12201"
  driver: "json-file"

x-healthcheck: &healthcheck
  interval: 5s
  timeout: 5s
  retries: 50
  start_period: 5s

x-spring-env: &spring-env
  server.port: 8080
  KAFKA_SERVERS: "kafka:9091"
  management.tracing.enabled: true
  management.otlp.tracing.endpoint: http://jaeger:4317
  SECRET_KEY: qweqweqweqweqweqweqweqweqweqweqrqwrqwrtweqtewqtweq
  API_KEY: qwtiuqwtiuqiwutiqwitiqwutiqwuituqwiotuqiowutiq
  app.client.balance: http://balanceservice:8080
  app.client.delivery: http://deliveryservice:8080
  app.client.notification: http://notificationservice:8080
  app.client.order: http://orderservice:8080
  app.client.product: http://productservice:8080
  app.client.stock: http://stockservice:8080
  app.client.user: http://userservice:8080

x-spring-conf: &spring-conf
  depends_on:
    postgres:
      condition: service_healthy
    redis:
      condition: service_healthy
    kafka:
      condition: service_healthy
  environment:
    <<: *spring-env
  logging: *logging
  expose: [ "8080" ]
  healthcheck:
    test: "curl --location --output /dev/null --head --silent --fail 127.0.0.1:8080/actuator/health || exit 1"
    <<: *healthcheck

services:
  nginx:
    image: nginx:1.27.0-alpine
    depends_on:
      balanceservice:
        condition: service_healthy
      deliveryservice:
        condition: service_healthy
      notificationservice:
        condition: service_healthy
      orderservice:
        condition: service_healthy
      productservice:
        condition: service_healthy
      stockservice:
        condition: service_healthy
      userservice:
        condition: service_healthy
    logging: *logging
    ports: [ "8080:80" ]
    volumes:
      - './nginx.conf:/etc/nginx/nginx.conf'

  balanceservice:
    build: ../balanceservice
    <<: *spring-conf

  deliveryservice:
    build: ../deliveryservice
    <<: *spring-conf

  notificationservice:
    build: ../notificationservice
    <<: *spring-conf

  orderservice:
    build: ../orderservice
    <<: *spring-conf

  productservice:
    build: ../productservice
    <<: *spring-conf

  stockservice:
    build: ../stockservice
    <<: *spring-conf

  userservice:
    build: ../userservice
    <<: *spring-conf

  postgres:
    image: postgres:alpine
    logging: *logging
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports: [ "5432:5432" ]
    command: >
      postgres 
      -c ssl=off
      -c wal_level=logical
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres -d postgres" ]
      <<: *healthcheck

  redis:
    image: redis:alpine
    ports: [ "6379:6379" ]
    logging: *logging
    environment:
      REDIS_DATABASES: 16
      REDIS_PASSWORD: redis
    healthcheck:
      test: "redis-cli ping || exit 1"
      <<: *healthcheck

  kafka:
    image: confluentinc/cp-kafka:7.5.5
    expose: [ "9091", "9092" ]
    logging: *logging
    environment:
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_NODE_ID: 1
      KAFKA_BROKER_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka:9091
      KAFKA_LISTENERS: BROKER://kafka:9091, CONTROLLER://kafka:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xms128m -Xmx1024m"
      KAFKA_LOG4J_ROOT_LOGLEVEL: 'WARN'
      KAFKA_LOG4J_LOGGERS: 'org.apache.zookeeper=WARN,org.apache.kafka=WARN,kafka=WARN,kafka.cluster=WARN,kafka.controller=WARN,kafka.coordinator=WARN,kafka.log=WARN,kafka.server=WARN,kafka.zookeeper=WARN,state.change.logger=WARN'
    healthcheck:
      test: "nc -z kafka 9091 || exit 1"
      <<: *healthcheck

  kafdrop:
    image: obsidiandynamics/kafdrop:4.0.1
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    ports: [ "9000:9000" ]
    environment:
      KAFKA_BROKERCONNECT: "kafka:9091"
    healthcheck:
      test: "curl --location --output /dev/null --head --silent --fail 127.0.0.1:9000 || exit 1"
      <<: *healthcheck

  grafana:
    image: grafana/grafana:11.0.0
    ports: [ "3000:3000" ]
    volumes:
      - ./grafana.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      #- ./config/grafana/plugins/app.yaml:/etc/grafana/provisioning/plugins/app.yaml
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_FEATURE_TOGGLES_ENABLE=accessControlOnCall lokiLogsDataplane
      #- GF_INSTALL_PLUGINS=https://storage.googleapis.com/integration-artifacts/grafana-lokiexplore-app/grafana-lokiexplore-app-latest.zip;grafana-lokiexplore-app

  loki:
    image: grafana/loki:3.0.0
    expose: [ "3100" ]
    command: -config.file=/etc/loki/loki.yaml
    volumes:
      - ./loki.yaml:/etc/loki/loki.yaml

  promtail:
    image: grafana/promtail:3.0.0
    depends_on:
      - loki
    command: -config.file=/etc/promtail/promtail.yaml
    volumes:
      - ./promtail.yaml:/etc/promtail/promtail.yaml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock

  kafkaconnect:
    build:
      dockerfile: ./kafkaconnect.Dockerfile
    logging: *logging
    restart: always
    expose: [ "8083" ]
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9091"
      CONNECT_GROUP_ID: "kafkaconnect"
      CONNECT_CONFIG_STORAGE_TOPIC: "kafkaconnect.config"
      CONNECT_OFFSET_STORAGE_TOPIC: "kafkaconnect.offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "kafkaconnect.status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafkaconnect"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: -1
      CONNECT_CONFIG_STORAGE_PARTITIONS: -1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: -1
      CONNECT_OFFSET_STORAGE_PARTITIONS: -1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: -1
      CONNECT_STATUS_STORAGE_PARTITIONS: -1
    healthcheck:
      test: "curl --fail --silent localhost:8083 | grep version || exit 1"
      <<: *healthcheck

  kafkaconnectinit:
    image: curlimages/curl
    logging: *logging
    restart: no
    depends_on:
      kafkaconnect:
        condition: service_healthy
    volumes:
      - ./kafkaconnect-postgres.json:/opt/kafkaconnect-postgres.json
      - ./kafkaconnect-redis.json:/opt/kafkaconnect-redis.json
    entrypoint: [ "/bin/sh", "-c" ]
    command: |
      "
      set -x
      sleep 1;
      curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" http://kafkaconnect:8083/connectors/ -d @/opt/kafkaconnect-postgres.json
      curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" http://kafkaconnect:8083/connectors/ -d @/opt/kafkaconnect-redis.json
      "

  jaeger:
    image: jaegertracing/all-in-one:latest
    logging: *logging
    ports: [ "16686:16686","4317:4317","4318:4318" ]
    environment:
      - COLLECTOR_OTLP_ENABLED=true